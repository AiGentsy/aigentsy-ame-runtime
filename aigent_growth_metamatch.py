
import requests
from bs4 import BeautifulSoup
from datetime import datetime
from openai import OpenAI

openai = OpenAI()

RENDER_ENDPOINT = "https://your-render-app.com/log-meta-match"
HEADERS = {"Content-Type": "application/json"}

def generate_keywords(traits):
    keywords = []
    if "legal" in traits:
        keywords += ["startup legal help", "nda template", "how to incorporate"]
    if "saas" in traits:
        keywords += ["build an app", "no-code MVP", "founder looking for dev"]
    if "marketing" in traits:
        keywords += ["SEO help", "growth agency", "ad funnel"]
    if "social" in traits:
        keywords += ["content creator", "grow on reels", "TikTok marketing"]
    if "custom" in traits or "universal" in traits:
        keywords += ["business idea", "need help launching", "how to start a company"]
    return keywords

def scrape_reddit(keyword, max_results=3):
    search_url = f"https://www.reddit.com/search/?q={keyword.replace(' ', '+')}&sort=new"
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(search_url, headers=headers)

    soup = BeautifulSoup(response.text, "html.parser")
    results = []
    for post in soup.select("a[data-click-id='body']")[:max_results]:
        title = post.get_text(strip=True)
        link = post["href"]
        full_url = link if link.startswith("http") else f"https://www.reddit.com{link}"
        results.append({
            "matchTarget": full_url,
            "matchPlatform": "reddit",
            "title": title
        })
    return results

def ai_discovery_matches(user_data, keyword):
    traits = ", ".join(user_data.get("traits", []))
    prompt = f"""
    You are an AI prospecting agent. The user has traits: {traits}.
    Their keyword is: {keyword}
    Find 1 result each from:
    - LinkedIn
    - TikTok
    - Instagram
    - Twitter
    - Google
    Return only URLs or user handles.
    """
    res = openai.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}]
    )
    text = res.choices[0].message.content
    matches = []
    for line in text.split("\n"):
        line = line.strip()
        if "linkedin.com" in line:
            matches.append({"matchTarget": line, "matchPlatform": "linkedin"})
        elif "tiktok.com" in line:
            matches.append({"matchTarget": line, "matchPlatform": "tiktok"})
        elif "instagram.com" in line:
            matches.append({"matchTarget": line, "matchPlatform": "instagram"})
        elif "twitter.com" in line or "x.com" in line:
            matches.append({"matchTarget": line, "matchPlatform": "twitter"})
        elif "http" in line:
            matches.append({"matchTarget": line, "matchPlatform": "google"})
    return matches

def generate_proposal_with_privacy(user_data, match):
    kit = user_data.get("prebuiltKit", "universal")
    username = user_data.get("username")
    profile = f"https://aigentsy.com/profile.html?user={username}"
    stripe = f"https://aigentsy.com/unlock/{kit}kit"
    timestamp = datetime.utcnow().isoformat()

    safe_contact_clause = (
        "This message was generated by an AI agent on behalf of an AiGentsy business owner. "
        "It is based on publicly available content or business queries you‚Äôve posted. "
        "If you prefer not to receive contact from AiGentsy-powered agents in the future, simply reply ‚Äúunsubscribe‚Äù or visit aigentsy.com/privacy-optout. "
        "We do not store or process any personal data beyond publicly accessible metadata used for match generation."
    )

    privacy_badge = (
        "üõ°Ô∏è Privacy-Conscious AI Match Engine ‚Äî No scraping of private data. "
        "No login or impersonation. All matches are based on public signals. "
        "Outbound contact is executed solely on behalf of verified users."
    )

    return {
        "matchSource": username,
        "kitPromoted": kit,
        "matchTarget": match["matchTarget"],
        "matchPlatform": match["matchPlatform"],
        "proposalType": "outbound",
        "profileLink": profile,
        "stripeLink": stripe,
        "timestamp": timestamp,
        "privacyBadge": privacy_badge,
        "safeContactClause": safe_contact_clause
    }

def log_to_backend(event):
    try:
        res = requests.post(RENDER_ENDPOINT, json=event, headers=HEADERS)
        if res.ok:
            print(f"‚úÖ Logged: {event['matchTarget']}")
        else:
            print(f"‚ùå Logging failed: {res.text}")
    except Exception as e:
        print(f"‚ùå Logging exception: {e}")

def run_metamatch_campaign(user_data):
    print(f"üöÄ Launching MetaMatch for {user_data['username']}")
    keywords = generate_keywords(user_data.get("traits", []))
    for keyword in keywords:
        reddit_matches = scrape_reddit(keyword)
        for match in reddit_matches:
            event = generate_proposal_with_privacy(user_data, match)
            log_to_backend(event)
        ai_matches = ai_discovery_matches(user_data, keyword)
        for match in ai_matches:
            event = generate_proposal_with_privacy(user_data, match)
            log_to_backend(event)
