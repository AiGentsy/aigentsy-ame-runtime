# aigent_growth_metamatch.py ‚Äî safe full replacement
import os, time, json, re
import requests
from helpers_net import http_post_json
from events import emit
from log_to_jsonbin_aam_patched import log_event
from guardrails import guard_ok
from bs4 import BeautifulSoup
from datetime import datetime

def emit_both(kind: str, data: dict):
    try:
        emit(kind, data)
    except Exception:
        pass
    try:
        log_event({"kind": kind, **(data or {})})
    except Exception:
        pass
try:
    from openai import OpenAI
except Exception:
    OpenAI = None  # library optional

# --- Config / clients ---
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY") or os.getenv("OPENROUTER_API_KEY")
OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
openai = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL) if (OpenAI and OPENAI_API_KEY) else None

# If your metamatch runs in a different service than FastAPI backend, set BACKEND_BASE in env.
# Example (Render): BACKEND_BASE=https://your-backend.onrender.com
BACKEND_BASE = (os.getenv("BACKEND_BASE") or "").rstrip("/")
SUBMIT_PROPOSAL_URL = f"{BACKEND_BASE}/submit_proposal" if BACKEND_BASE else "/submit_proposal"

HTTP = requests.Session()
HTTP.headers.update({"User-Agent": "AiGentsy-MetaMatch/1.0"})

# --- Helpers ---
def generate_keywords(traits):
    """Derive prospecting keywords from user traits (privacy-safe, generic)."""
    traits = traits or []
    kw = []
    if "legal" in traits: kw += ["startup legal help", "nda template", "incorporate llc"]
    if "saas" in traits: kw += ["build an app", "no-code MVP", "hire developer"]
    if "marketing" in traits: kw += ["SEO help", "growth agency", "ad funnel"]
    if "social" in traits: kw += ["content creator help", "grow on reels", "tiktok marketing"]
    if "custom" in traits or "universal" in traits: kw += ["business idea", "launch my business", "need help launching"]
    # stable de-dupe
    seen = set(); out=[]
    for k in kw:
        if k not in seen:
            out.append(k); seen.add(k)
    return out or ["launch my business", "need help launching"]

def scrape_reddit(keyword, max_results=3, timeout=8):
    """Lightweight HTML fetch ‚Äî best-effort, returns recent posts as prospects."""
    try:
        url = f"https://www.reddit.com/search/?q={keyword.replace(' ', '+')}&sort=new"
        r = HTTP.get(url, timeout=timeout)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")
        results = []
        for post in soup.select("a[data-click-id='body']")[:max_results]:
            title = post.get_text(strip=True)[:140]
            link = post.get("href", "") or ""
            full_url = link if link.startswith("http") else f"https://www.reddit.com{link}"
            if not full_url: 
                continue
            results.append({"matchTarget": full_url, "matchPlatform": "reddit", "title": title})
        return results
    except Exception:
        return []

def ai_discovery_matches(user_data, keyword):
    """
    Optional LLM-assisted discovery (links only).
    Skips gracefully if no key or library.
    """
    if not openai:
        return []
    traits = ", ".join(user_data.get("traits", []))
    prompt = f"""
You are an AI prospecting agent. Traits: {traits}. Keyword: {keyword}.
Return up to 5 prospects as raw links (prefer LinkedIn, TikTok, Instagram, X/Twitter, or relevant sites).
One per line. No commentary, no bullets.
"""
    try:
        res = openai.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[{"role":"user","content":prompt}],
            temperature=0.4
        )
        text = (res.choices[0].message.content or "").strip()
        matches=[]
        for line in text.splitlines():
            line=line.strip()
            if not line: 
                continue
            if not re.search(r"https?://", line): 
                continue
            platform = "web"
            if "linkedin.com" in line: platform="linkedin"
            elif "tiktok.com" in line: platform="tiktok"
            elif "instagram.com" in line: platform="instagram"
            elif "twitter.com" in line or "x.com" in line: platform="twitter"
            matches.append({"matchTarget": line, "matchPlatform": platform})
        return matches[:5]
    except Exception:
        return []

def generate_proposal_with_privacy(user_data, match):
    """Compose a privacy-conscious, quick-win proposal payload."""
    kit = user_data.get("prebuiltKit") or "universal"
    username = user_data.get("username") or user_data.get("consent",{}).get("username") or "unknown"
    profile = f"https://aigentsy.com/profile.html?user={username}"
    stripe = f"https://aigentsy.com/unlock/{kit}kit"
    timestamp = datetime.utcnow().isoformat()

    safe_contact_clause = (
        "Generated by an AiGentsy-powered agent on behalf of a business owner. "
        "Based on public business signals only. Reply 'unsubscribe' or visit aigentsy.com/privacy-optout."
    )
    privacy_badge = (
        "üõ°Ô∏è Privacy-Conscious AI Match: No private data scraping; public metadata only; verified user outbound."
    )
    title = f"{kit.title()} Quick-Win Offer"
    details = (f"We can deliver a {kit} quick-win within 24‚Äì48h.\n"
               f"Profile: {profile}\nUnlock: {stripe}\n\n"
               f"{privacy_badge}\n{safe_contact_clause}")

    return {
        "sender": username,
        "recipient": match.get("matchTarget"),
        "title": title,
        "details": details,
        "link": stripe,
        "timestamp": timestamp,
        "meta": {
            "matchPlatform": match.get("matchPlatform"),
            "profileLink": profile,
            "kitPromoted": kit,
            "privacyBadge": privacy_badge
        }
    }

def submit_proposal(proposal):
    """Write an actual proposal to the backend (FastAPI: POST /submit_proposal)."""
    try:
        r = HTTP.post(SUBMIT_PROPOSAL_URL, json=proposal, timeout=10)
        ok = (r.status_code // 100) == 2
        if not ok:
            print("‚ùå submit_proposal failed:", r.status_code, r.text[:200])
        return ok
    except Exception as e:
        print("‚ùå submit_proposal exception:", e)
        return False

def run_metamatch_campaign(user_data, per_keyword_limit=3, sleep_between=1.0):
    """
    Privacy-safe MetaMatch campaign:
    - Derives keywords from traits
    - Scrapes a few recent public prospects
    - Optionally asks LLM to find links (if key configured)
    - Submits real proposals to backend
    """
    username = user_data.get("username") or user_data.get("consent",{}).get("username") or "unknown"
    print(f"üöÄ Launching MetaMatch for {username}")
    keywords = generate_keywords(user_data.get("traits", []))
    seen_targets = set()
    submitted = 0

    for kw in keywords:
        # 1) reddit (HTML fetch ‚Äì best-effort)
        for match in scrape_reddit(kw, max_results=per_keyword_limit):
            tgt = match["matchTarget"]
            if tgt in seen_targets: 
                continue
            seen_targets.add(tgt)
            proposal = generate_proposal_with_privacy(user_data, match)
            if submit_proposal(proposal): 
                submitted += 1
            time.sleep(sleep_between)

        # 2) LLM-assisted discovery (if key present)
        for match in ai_discovery_matches(user_data, kw):
            tgt = match["matchTarget"]
            if tgt in seen_targets: 
                continue
            seen_targets.add(tgt)
            proposal = generate_proposal_with_privacy(user_data, match)
            if submit_proposal(proposal): 
                submitted += 1
            time.sleep(sleep_between)

    return {"ok": True, "submitted": submitted, "uniqueTargets": len(seen_targets)}
